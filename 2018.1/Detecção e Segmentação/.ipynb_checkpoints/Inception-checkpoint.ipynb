{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.datasets import mnist\n",
    "import keras.layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, BatchNormalization, Concatenate, AveragePooling2D\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers.merge import concatenate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introdução\n",
    "\n",
    "Deep Learning atualmente é uma abordagem considerada estado da arte para muitas aplicações, principalmente aquelas envolvendo classificação de imagens devido ao desafio ImageNet, que resultou em arquiteturas complexas de Deep Learning como AlexNet, VGG-16, GoogleLeNet e ResNet. O gráfico abaixo ilustra a performance dessas arquiteturas utilizando a base do ImageNet, em que, a arquitetura ResNet possui resultados melhores que o humano.\n",
    "\n",
    "![alt text](imgs/imagenet.png \"Title\")\n",
    "\n",
    "Essas arquiteturas podem ser implementadas utilizando a API Keras a partir de modelos não sequenciais. Assim, esse notebook ilustra uma implementação de uma rede com blocos da arquitetura Inceptionv4 com blocos residuais. A partir dessa implementação, é possível implementar arquiteturas diferenciadas de Deep Learning para resolver diversos problemas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inception v4\n",
    "\n",
    "Uma arquitetura Inception possui uma estrutura dividida em dois blocos principais: stem e reduction. Stem é o módulo base da arquitetura, formado por uma sequência de redes convolucionais e pooling, os módulos reduction, por outro lado, são módulos em que cada camada é constituída por uma concatenação de convoluções e pooling. \n",
    "\n",
    "Além desses dois blocos principais, a Inception possui também uma versão com blocos residuais, conforme Figura abaixo. Esses blocos aumentam consideravelmente a performance da rede e aceleram também o treinamento. \n",
    "\n",
    "![alt text](imgs/architecture.png \"Title\")\n",
    "\n",
    "Baseado nisso, as seções desse notebook são organizadas da seguinte forma:\n",
    "* Stem: ilustra a implementação do bloco stem darede\n",
    "* Reduction-A: ilustra a implementação do primeiro bloco reduction da arquitetura\n",
    "* Resnet-A: ilustra a implementação do primeiro bloco residual \n",
    "* Reduction-B: ilustra a implementação do segundo bloco reduction\n",
    "* Resnet-B: ilustra a implementação do segundo bloco residual\n",
    "* Reduction-C: ilustra a implementação do terceiro bloco reduction\n",
    "* Construindo a arquitetura Inceptionv4: ilustra o dataflow da arquitetura e realiza o treinamento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stem\n",
    "\n",
    "O bloco stem é formado inicialmente por três camadas convolucionais seguidas, cada uma, por normalização do batch, sendo a primeira delas uma camada com 32 filtros de dimensão 3x3 e stride 2x2 e sem padding (valid). Uma vez que o modelo não é sequencial, a implementação do Keras não é definida como model=Sequential() e não possui o método model.add(camada). Ao invés disso, atribuiu-se a cada camada uma variável, passando-se como parâmetro dessa camada a camada anterior.\n",
    "\n",
    "Por exemplo, para a primeira camada, chamamos o método do Keras Conv2D, atribuindo seu retorno a variável model. Além disso, para definir a entrada, após o Conv2D colocamos entre parentese (input_img), que representa a entrada da rede de dimensões 32x32x3. Em seguida, chamamos o método BatchNormalization atribuindo seu resultado novamente a variável model.\n",
    "\n",
    "Após a implementação dessas três primeiras camadas, tem-se uma camada formada pela concatenação de uma camada convolucional com uma camada pooling. Para isso, definimos duas variáveis auxiliares (branch0 e branch1) e atribuimos a cada uma as respectivas camadas convolucionais e pooling. Após isso, utiliza-se o método concatenate do Keras para formar a camada da rede. Da mesma forma, podemos definir as demais camadas do Stem até a última concatenação, retornando-se o modelo final.\n",
    "\n",
    "![alt text](imgs/stem.png \"Title\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(input_img):\n",
    "    model = Conv2D(32, (3,3), strides=(2,2), padding='valid', activation='relu',name='stem')(input_img)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Conv2D(32, (3,3), padding='valid', activation='relu', name = 'conv1')(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Conv2D(64, (3,3), padding='same', activation='relu', name = 'conv2')(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    branch0 = MaxPooling2D((3,3), strides=(2,2), padding='valid')(model)\n",
    "    branch1 = Conv2D(96, (3,3), strides=(2,2), padding='valid', activation='relu', name = 'conv3_branch1')(model)\n",
    "    branch1 = BatchNormalization()(branch1)\n",
    "    model = concatenate([branch0, branch1], axis=-1)\n",
    "    branch0 = Conv2D(64, (1,1), padding='same', activation='relu', name = 'conv5_branch0')(model)\n",
    "    branch0 = BatchNormalization()(branch0)\n",
    "    branch0 = Conv2D(96, (3,3), padding='valid', activation='relu', name='conv6_branch0')(branch0)\n",
    "    branch0 = BatchNormalization()(branch0)\n",
    "    branch1 = Conv2D(64, (1,1), padding='same', activation='relu',name='conv7_branch1')(model)\n",
    "    branch1 = Conv2D(64, (7,1), padding='same', activation='relu',name='conv8_branch1')(branch1)\n",
    "    branch1 = BatchNormalization()(branch1)\n",
    "    branch1 = Conv2D(64, (1,7), padding='same', activation='relu',name='conv9_branch1')(branch1)\n",
    "    branch1 = BatchNormalization()(branch1)\n",
    "    branch1 = Conv2D(96, (3,3), padding='valid', activation='relu',name='conv10_branch1')(branch1)\n",
    "    branch1 = BatchNormalization()(branch1)\n",
    "    model = concatenate([branch0, branch1], axis=-1)\n",
    "    branch0 = Conv2D(192, (3,3), padding='valid', activation='relu', name = 'conv11_branch0')(model)\n",
    "    branch0 = BatchNormalization()(branch0)\n",
    "    branch1 = MaxPooling2D()(model)\n",
    "    model = concatenate([branch0, branch1], axis=-1)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resnet A\n",
    "\n",
    "Para implementação dos blocos residuais, inicialmente cria-se três branches (branch0,branch1 e branch2) e concatenamos o resultado das três para formação da camada na rede. Feito isso, essa camada é utilizada como entrada para uma camada convolucional com 384 filtros.\n",
    "\n",
    "Por fim, para fazer um modelo residual, utiliza-se a função add do Keras passando-se como parâmetro o modelo resultante do bloco anterior (stem) e o modelo atual da camada (x). O resultado disso é o modelo de saída desse bloco.\n",
    "\n",
    "![alt text](imgs/resnetA.png \"Title\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception_resnet_A(model):\n",
    "    branch0 = Conv2D(32, (1,1), padding='same', activation='relu',name='resnet_a_conv1_branch0')(model)\n",
    "    branch0 = BatchNormalization()(branch0)\n",
    "    branch1 = Conv2D(32, (1,1), padding='same', activation='relu',name='resnet_a_conv2_branch1')(model)\n",
    "    branch1 = BatchNormalization()(branch1)\n",
    "    branch1 = Conv2D(32, (3,3), padding='same', activation='relu',name='resnet_a_conv3_branch1')(branch1)\n",
    "    branch1 = BatchNormalization()(branch1)\n",
    "    branch2 = Conv2D(32, (1,1), padding='same', activation='relu',name='resnet_a_conv4_branch1')(model)\n",
    "    branch2 = BatchNormalization()(branch2)\n",
    "    branch2 = Conv2D(48, (3,3), padding='same', activation='relu',name='resnet_a_conv5_branch1')(branch2)\n",
    "    branch2 = BatchNormalization()(branch2)\n",
    "    branch2 = Conv2D(64, (3,3), padding='same', activation='relu',name='resnet_a_conv6_branch1')(branch2)\n",
    "    branch2 = BatchNormalization()(branch2)\n",
    "    x = concatenate([branch0, branch1,branch2], axis=-1)\n",
    "    x = Conv2D(384, (1,1), padding='same', activation='relu',name='resnet_a_conv7')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    model = keras.layers.add([x, model])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduction A\n",
    "\n",
    "Os blocos reduction são formados em geral por três branches principais, variando-se a quantidade de filtros de cada branch. A estrutura, representada pela Figura abaixo, possui um branch inicial apenas com uma camada pooling de dimensão 3x3, enquanto o segundo branch possui uma camada convolucional de dimensão 3x3 e o último três camadas convolucionais. Ao final, as três branches são concatenadas e resultam na saída desse bloco.\n",
    "\n",
    "![alt text](imgs/reduction.png \"Title\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduction_a(model):\n",
    "    branch0 = MaxPooling2D((3,3), strides=(2,2), padding='same',name='reduction_a')(model)\n",
    "    branch1 = Conv2D(384, (3,3), strides=(2,2), padding='same', activation='relu')(model)\n",
    "    branch1 = BatchNormalization()(branch1)\n",
    "    branch2 = Conv2D(192, (1,1), padding='same', activation='relu')(model)\n",
    "    branch2 = BatchNormalization()(branch2)\n",
    "    branch2 = Conv2D(224, (3,3), padding='same', activation='relu')(branch2)\n",
    "    branch2 = BatchNormalization()(branch2)\n",
    "    branch2 = Conv2D(256, (3,3), strides=(2,2), padding='same', activation='relu')(branch2)\n",
    "    branch2 = BatchNormalization()(branch2)\n",
    "    model = concatenate([branch0,branch1,branch2],axis=-1)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resnet-B\n",
    "\n",
    "De forma semelhante ao primeiro bloco ResNet, define-se duas branches e o resultado delas é utilizado como entrada de uma camada convolucional. Ao final, utilizamos o método add para formar a camada residual, utilizando-se como parâmetros o resultado da camada anterior (reduction-A) e o resultado dessa camada (a concatenação dos três branches).\n",
    "![alt text](imgs/resnet-b.png \"Title\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception_resnet_b(model):\n",
    "    branch0 =  Conv2D(128, (1,1), padding='same', activation='relu', name='resnet_b')(model)\n",
    "    branch0 = BatchNormalization()(branch0)\n",
    "    branch0 =  Conv2D(160, (1,7), padding='same', activation='relu')(branch0)\n",
    "    branch0 = BatchNormalization()(branch0)\n",
    "    branch0 =  Conv2D(192, (7,1), padding='same', activation='relu')(branch0)\n",
    "    branch0 = BatchNormalization()(branch0)   \n",
    "    \n",
    "    branch1 =  Conv2D(192, (1,1), padding='same', activation='relu')(model)\n",
    "    branch1 = BatchNormalization()(branch1)\n",
    "    x = concatenate([branch1, branch0], axis=-1)\n",
    "    branch1 =  Conv2D(1024, (1,1), padding='same', activation='relu')(x)\n",
    "    branch1 = BatchNormalization()(branch1)\n",
    "    model = keras.layers.add([branch1, model])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduction B\n",
    "\n",
    "Para o segundo módulo reduction, utiliza-se quatro banches, uma apenas com uma camada pooling, dois com duas camadas convolucionais respectivamente e um último branch três camadas convolucionais. Após isso, os branches são concatenados e utilizados como saída do bloco.\n",
    "\n",
    "![alt text](imgs/reduction-b.png \"Title\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduction_b(model):\n",
    "    branch0 = MaxPooling2D((3,3), strides=(2,2), padding='same', name='reduction_b')(model)\n",
    "    branch1 = Conv2D(256, (1,1), padding='same', activation='relu')(model)\n",
    "    branch1 = BatchNormalization()(branch1)\n",
    "    branch1 = Conv2D(384, (3,3), padding='same', activation='relu')(branch1)\n",
    "    branch1 = BatchNormalization()(branch1)\n",
    "    branch2 = Conv2D(256, (1,1), padding='same', activation='relu')(model)\n",
    "    branch2 = BatchNormalization()(branch2)\n",
    "    branch2 = Conv2D(288, (3,3), padding='same', activation='relu')(branch2)\n",
    "    branch2 = BatchNormalization()(branch2)\n",
    "    branch3 = Conv2D(256, (1,1), padding='same', activation='relu')(model)\n",
    "    branch3 = BatchNormalization()(branch3)\n",
    "    branch3 = Conv2D(288, (3,3), padding='same', activation='relu')(branch3)\n",
    "    branch3 = BatchNormalization()(branch3)\n",
    "    branch3 = Conv2D(320, (1,1), padding='same', activation='relu')(branch3)\n",
    "    branch3 = BatchNormalization()(branch3)\n",
    "    model = concatenate([branch0,branch1,branch2,branch3], axis=-1)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet-C\n",
    "\n",
    "Para o último bloco residual, cria-se duas branches com uma camada convolucional e três camadas convolucionais respectivamente. A saída das duas branches é concatenada e utilizada como entrada de uma camada convolucional e por fim, utiliza-se o método add do Keras para finalizar o bloco residual, utilizando-se como parâmetros o modelo de saída do bloco anterior (reduction) e o resultado desta camada (a concatenação dos três branches).\n",
    "\n",
    "![alt text](imgs/resnet-c.png \"Title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception_resnet_c(model):\n",
    "    branch0 =  Conv2D(192, (1,1), padding='same', activation='relu', name = 'resnet_c')(model)\n",
    "    branch0 = BatchNormalization()(branch0)\n",
    "    branch0 =  Conv2D(224, (1,3), padding='same', activation='relu')(branch0)\n",
    "    branch0 = BatchNormalization()(branch0)\n",
    "    branch0 =  Conv2D(256, (3,1), padding='same', activation='relu')(branch0)\n",
    "    branch0 = BatchNormalization()(branch0)   \n",
    "    \n",
    "    branch1 =  Conv2D(192, (1,1), padding='same', activation='relu')(model)\n",
    "    branch1 = BatchNormalization()(branch1)\n",
    "    x = concatenate([branch1, branch0], axis=-1)\n",
    "    branch1 =  Conv2D(2016, (1,1), padding='same', activation='relu')(x)\n",
    "    branch1 = BatchNormalization()(branch1)\n",
    "    model = keras.layers.add([branch1, model])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construindo uma arquitetura Inception\n",
    "\n",
    "Após definir todos os blocos da arquitetura, pode-se criar o modelo final do Keras. Para isso, construimos o modelo seguindo a ordem da arquitetura principal da Figura 1. Após isso, adiciona-se uma camada Dropout e a camada Dense. Para finalizar, cria-se a instância Model do Keras passando-se como parâmetros a dimensão de entrada da imagem e o modelo final da camada Dense (out). Com isso o modelo é criado e pode ser treinado da mesma forma que qualquer arquitetura simples no Keras utilizando os métodos compile e fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "from keras.utils import np_utils\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "from keras.layers import Input\n",
    "input_img = Input(shape = (32, 32, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1062: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:2550: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1123: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/8\n",
      "40000/40000 [==============================] - 1086s - loss: 4.3234 - acc: 0.2611 - val_loss: 3.1176 - val_acc: 0.3252\n",
      "Epoch 2/8\n",
      "40000/40000 [==============================] - 940s - loss: 2.7996 - acc: 0.2793 - val_loss: 6.0659 - val_acc: 0.1759\n",
      "Epoch 3/8\n",
      "13184/40000 [========>.....................] - ETA: 805s - loss: 2.6662 - acc: 0.2689"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-72d1aaf029b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtbCallBack\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1483\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1484\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1485\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1487\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m   1138\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1140\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1141\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2073\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2074\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 2075\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   2076\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2077\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    885\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 887\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    888\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1108\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1110\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1111\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1284\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1285\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1286\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1287\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1288\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1290\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1291\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1292\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1293\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1275\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1276\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1277\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1279\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1365\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1366\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "\n",
    "st = stem(input_img)\n",
    "resnetA = inception_resnet_A(st)\n",
    "reductionA = reduction_a(resnetA)\n",
    "resnetB = inception_resnet_b(reductionA)\n",
    "reductionB = reduction_b(resnetB)\n",
    "resnetC = inception_resnet_c(reductionB)\n",
    "#average_pool = AveragePooling2D()(resnetC)\n",
    "drop = Dropout(0.8)(resnetC)\n",
    "flatten = Flatten()(drop)\n",
    "out = Dense(10, activation='softmax')(flatten)\n",
    "tbCallBack = keras.callbacks.TensorBoard(log_dir='./Graph', histogram_freq=0, write_graph=True, write_images=True)\n",
    "\n",
    "net = Model(inputs = input_img, outputs = out)\n",
    "net.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "net.fit(X_train, y_train, validation_split=(0.2), epochs=8, batch_size=32,callbacks=[tbCallBack])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
